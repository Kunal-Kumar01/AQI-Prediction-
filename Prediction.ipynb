{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 09:25:24,024 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-24 09:25:24,323 INFO: Initializing external client\n",
      "2025-01-24 09:25:24,328 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-24 09:25:27,386 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1211546\n",
      "Connected to Hopsworks Feature Store\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.36s) \n",
      "Data fetched successfully from the feature store!\n",
      "Loaded model: Linear_Regression, version: 1)... DONE\n",
      "Retraining Linear_Regression on the training dataset...\n",
      "Model performance on test dataset:\n",
      "  RMSE: 1.5000375566646494e-15\n",
      "  MAE: 1.1818757162853616e-15\n",
      "  R²: 1.0\n",
      "Predicted AQI for the next 3 days:\n",
      "         Date  Predicted_AQI\n",
      "0  2025-01-24          55.98\n",
      "1  2025-01-25          55.98\n",
      "2  2025-01-26          55.98\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# --- Step 1: Connect to Hopsworks and Fetch Data from Feature Store ---\n",
    "project = hopsworks.login(api_key_value=\"KpnqasHfb4WsGo1Z.jp7TSl48y51FcnnVvfgVgRk7cot4me3LXYlde0JOWpnzB0clm5x9Fre7tijqumxU\")  # Replace with your API key\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "print(\"Connected to Hopsworks Feature Store\")\n",
    "\n",
    "# Get the feature group\n",
    "feature_group = fs.get_feature_group(name=\"aqi_features\", version=1)\n",
    "\n",
    "# Fetch data as a Pandas DataFrame\n",
    "data = feature_group.read()\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop(columns=[\"aqi\"])  # Replace 'aqi' with your actual target column\n",
    "target = data[\"aqi\"]\n",
    "\n",
    "print(\"Data fetched successfully from the feature store!\")\n",
    "\n",
    "# --- Step 2: Preprocess Features ---\n",
    "# Transform 'date' column into numeric features\n",
    "features[\"date\"] = pd.to_datetime(features[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Extract useful numeric features from 'date'\n",
    "features[\"date_year\"] = features[\"date\"].dt.year\n",
    "features[\"date_month\"] = features[\"date\"].dt.month\n",
    "features[\"date_day\"] = features[\"date\"].dt.day\n",
    "features[\"date_hour\"] = features[\"date\"].dt.hour\n",
    "features[\"date_minute\"] = features[\"date\"].dt.minute\n",
    "\n",
    "# Convert 'date' to a numeric timestamp\n",
    "features[\"date_timestamp\"] = features[\"date\"].view('int64') // 10**9\n",
    "\n",
    "# Drop the original 'date' column\n",
    "features = features.drop(columns=[\"date\"], errors=\"ignore\")\n",
    "\n",
    "# --- Step 3: Train-Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Step 4: Apply Feature Scaling ---\n",
    "scaler = MinMaxScaler()  # Use MinMaxScaler for scaling between 0 and 1\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Step 5: Connect to Model Registry and Fetch the Best Model ---\n",
    "mr = project.get_model_registry()\n",
    "model_name = \"Linear_Regression\"  # Replace with the name of your model\n",
    "model_version = 1  # Use the appropriate version\n",
    "\n",
    "model_registry = mr.get_model(model_name, version=model_version)\n",
    "model_dir = model_registry.download()\n",
    "model_file = f\"{model_dir}/best_model.pkl\"\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(model_file)\n",
    "print(f\"Loaded model: {model_name}, version: {model_version}\")\n",
    "\n",
    "# --- Step 6: Retrain the Model ---\n",
    "print(f\"Retraining {model_name} on the training dataset...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model performance on test dataset:\")\n",
    "print(f\"  RMSE: {rmse}\")\n",
    "print(f\"  MAE: {mae}\")\n",
    "print(f\"  R²: {r2}\")\n",
    "\n",
    "# --- Step 7: Predict AQI for the Next 3 Days ---\n",
    "# Get today's date and generate the next 3 days\n",
    "#start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)  # Today's date, time set to midnight\n",
    "#start date is tomorrow\n",
    "start_date = start_date + timedelta(days=1)\n",
    "days_to_predict = 3\n",
    "future_dates = [start_date + timedelta(days=i) for i in range(days_to_predict)]\n",
    "\n",
    "# Create a DataFrame for the future dates with all required features\n",
    "future_features = pd.DataFrame({\n",
    "    \"date_year\": [date.year for date in future_dates],\n",
    "    \"date_month\": [date.month for date in future_dates],\n",
    "    \"date_day\": [date.day for date in future_dates],\n",
    "    \"date_hour\": [12] * days_to_predict,  # Assuming predictions are made for midday\n",
    "    \"date_minute\": [0] * days_to_predict,  # Assuming predictions are made for the 0th minute\n",
    "    \"date_timestamp\": [int(date.timestamp()) for date in future_dates]  # Numeric timestamp\n",
    "})\n",
    "\n",
    "# Add missing columns with default values\n",
    "required_columns = features.columns.tolist()  # Get all columns used in training\n",
    "for col in required_columns:\n",
    "    if col not in future_features.columns:\n",
    "        future_features[col] = 0  # Fill missing columns with default value (e.g., 0)\n",
    "\n",
    "# Ensure column order matches the training data\n",
    "future_features = future_features[required_columns]\n",
    "\n",
    "# Scale the future features using the same scaler\n",
    "future_features_scaled = scaler.transform(future_features)\n",
    "\n",
    "# Predict AQI using the retrained model\n",
    "predicted_aqi = model.predict(future_features_scaled)\n",
    "\n",
    "# Combine the future dates with their predictions\n",
    "prediction_results = pd.DataFrame({\n",
    "    \"Date\": [date.strftime(\"%Y-%m-%d\") for date in future_dates],\n",
    "    \"Predicted_AQI\": np.round(predicted_aqi, 2)  # Round AQI to 2 decimal places\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(\"Predicted AQI for the next 3 days:\")\n",
    "print(prediction_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `prediction_results` to a file\n",
    "prediction_results.to_pickle(\"prediction_results.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
